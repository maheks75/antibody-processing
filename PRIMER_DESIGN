# using the reads dataste we can run igblast to the reads, so that we get annotated file, if the primer target region lies within FR1-3, then we can align the aa part of sequence for eg FR1 - FR1_AA
#then see what are the multiple regions that are popping up to be constant. It is seen that choosing different targets yileds better rresults with less primers required to capture the diversity.

#step 1 - if needed to extarct a column from igblast file if required
import pandas as pd

data = pd.read_csv('FInal_combined_igblast_AL121122.csv') 
col_cdr = data['fwr3_aa']
with open('frw3.fasta', 'w') as file:
    for j, se  in enumerate(col_cdr):
        if '*' not in str(se) and not pd.isna(se):
            header = f'seq{j + 1}'
            file.write(f'>{header}\n{se}\n') #After this step perform MSA of the aa seqs to see multiple regions. 

#create translated frames-step2
from Bio.Seq import Seq
from Bio import SeqIO

with open('remaining_1_trans', 'a') as file:
    for i, record in enumerate(SeqIO.parse('remaining_1', "fasta")):
        seq = str(record.seq)
        header = f'{i+1}'
        trans_first = str(Seq(seq).translate())
        seq_second = seq[1:]
        trans_second = str(Seq(seq_second).translate())
        seq_third = seq[2:]
        trans_third = str(Seq(seq_third).translate())
        output_parts = []
        if '*' not in trans_first and '*' not in trans_second and '*' not in trans_third and 'X' not in trans_first and 'X' not in trans_second and 'X' not in trans_third:
            output_parts.append(f'{trans_first}:{trans_second}:{trans_third}')
            output_line = ''.join(output_parts)
            if output_parts:
                file.write(f'{header}:{seq}:{output_line}\n') #do this step first for full reads, run step-3 with different targets, observe co-ordinates then do trimming and re run on trimmed reads.


#fasta/fastq trimming

from Bio import SeqIO
input_fastq_file = "remaining"
output_file = "MERGED_TRIM.fasta"
with open(output_file, 'w') as output_handle_with_5g:
    for i, record in enumerate(SeqIO.parse(input_fastq_file, "fasta")):
        sequence_data = str(record.seq)[10:100]
        header = record.description
        if len(sequence_data) >= 90:
                print(len(sequence_data))
                output_handle_with_5g.write(f">{header}\n{sequence_data}\n")

#search frames for conserved region and create separate file for mismatches-step3

import os
def process_file(input_file, target_seq):
    with open(input_file, 'r') as file:
        lines = file.readlines()

    folder_path = "/home/mahek0424/basespace/primer/"

    for line in lines:
        parts = line.strip().split(':')
        header = parts[0]
        seq = parts[1]
        parts = [p for p in parts[2:]]

        output, min_mismatches = find_minimum_mismatch_region(header, seq, parts, target_seq)

        if output:
            output_file = os.path.join(folder_path, f'tav_trans_{min_mismatches}_scr2.out')
            output_line = f'{header}:{seq}:{output}:{min_mismatches}'

            with open(output_file, 'a') as file:
                file.write(output_line + '\n')

def find_minimum_mismatch_region(header, seq, parts, target_seq):
    min_mismatches = float('inf')
    best_match = None

    for part_index, part in enumerate(parts):
            for i in range(len(part) - len(target_seq) + 1):
                window = part[i:i + len(target_seq)]
                if '*' not in window and 'X' not in window:
                    mismatches = sum(a != b for a, b in zip(window, target_seq))
                    if mismatches < min_mismatches:
                        min_mismatches = mismatches
                        best_match = (i + 1, window, part_index + 1)

    if best_match:
        target_index, window, part_index = best_match
        output = f'{part_index}:{target_index}:{window}'
        return output, min_mismatches
    else:
        return '', float('inf')
input_file = 'remaining_part2_trans'
target_seq = 'TAVYYC'
process_file(input_file, target_seq)

#create fasta file of step3-step4

def process_line(line):
    # Split the line into parts
    parts = line.split(':')
    header = parts[0]
    
    if len(parts) > 1:
        sequence = parts[1]
        if len(parts) > 2:
            start_index = int(parts[2]) - 1
            final_index = (int(parts[3]) - 1) * 3
            seq1 = sequence[start_index:]
            result = seq1[final_index:final_index+18]
        else:
            result = sequence
    else:
        result = ""  
    
    return header, result
with open('ALK_trans_1_scr2.out', 'r') as input_file:
    # Open the output file for writing
    with open('ALK_result1','w') as output_file:
        # Process each line
        for line in input_file:
            header, result = process_line(line.strip())
            output_file.write(f'>{header}\n{result}\n')
print("Processed the input file and wrote the results to")

calculate base diversity from a fasta file given out of step5
import os
os.chdir('/home/mahek0424/basespace/primer/')
from Bio import SeqIO
seq_list2 = []
for i, record in enumerate(SeqIO.parse('remaining_1', 'fasta')):
    seqs  = record.seq
    seq_list2.append(seqs)
for sl in seq_list2:
    consensus_sequence = ""
    for k in range(len(sl)):
        BASES_CALCULATE = {"A": 0, "C": 0, "G": 0, "T": 0, "-": 0, 'N': 0}
        bases = ["A", "C", "G", "T", "N", "-"]
        for j in range(len(seq_list2)):
            if len(seq_list2[j]) > k:
                base = seq_list2[j][k]
                BASES_CALCULATE[base] += 1

        total_sequences = len(seq_list2)
        print(f'Position {k}:', end=' ')
        for base, count in BASES_CALCULATE.items():
            frequency = (count / total_sequences) * 100
            print(f'{base}: {frequency:.2f}%', end=', ')
        print()

        most_common_base = max(BASES_CALCULATE, key=BASES_CALCULATE.get)
        consensus_sequence += most_common_base
        #print(consensus_sequence)

#calculate reads detected by primer and create an output file with reads pulled out by primer- step7

from Bio import SeqIO
import re
 
input_fasta_file = "/home/mahek0424/basespace/primer/f3_reads"

output_file_with_targets = "p5_try_al_p4.fasta"
target_patterns = [r"PRIMERS", 
                    ]

count = 0 
with open(output_file_with_targets, 'w') as output_handle:
    for i, record in enumerate(SeqIO.parse(input_fasta_file, "fasta")):
        sequence_data = str(record.seq)
        target_positions = {}
        for j, pattern in enumerate(target_patterns, 1):
            positions = [m.start() for m in re.finditer(pattern, sequence_data, re.IGNORECASE)]
            target_positions[f'Target{j}'] = positions
        
        if any(target_positions.values()):
            count += 1
            header = f"{record.id}|positions={target_positions}"
            #output_handle.write(f">{header}\n{sequence_data}\n")
    print(count)     

#calculate reads not detected by primer and create an output file with reads not pulled out by primer- nostep perform if needed

from Bio import SeqIO
import re

input_fasta_file = 'remaining_f3'
output_file_with_targets = "remaining_1"

#target_patterns = [#r"PRIMERS",
                   # ]
target_patterns = [r"PRIMERS",
                    ]


with open(output_file_with_targets, 'w') as output_handle:
    for i, record in enumerate(SeqIO.parse(input_fasta_file, "fasta")):
        sequence_data = str(record.seq)
        target_positions = {}
        for j, pattern in enumerate(target_patterns, 1):
            positions = [m.start() for m in re.finditer(pattern, sequence_data, re.IGNORECASE)]
            target_positions[f'Target{j}'] = positions

        if not any(target_positions.values()):
            output_handle.write(f">{record.id}\n{sequence_data}\n")

# check- parse FASTA file and find reads with target at position furtherafter 145
def parse_fasta(file_path):
    sequences = {}
    current_header = None
    with open(file_path, 'r') as f:
        for line in f:
            if line.startswith('>'):
                current_header = line.strip()
                sequences[current_header] = ''
            else:
                sequences[current_header] += line.strip()
    return sequences
 
sequences = parse_fasta('p5_try_al_p4.fasta')
with open('350_check_al_p4_fasta.fasta', 'w') as out_file:
    for header, seq in sequences.items():
        numbers = [int(num) for num in header.split('[')[1].split(']')[0].split(',') if num.strip ()]
        if any(num < 350 for num in numbers):
            # Write the header and sequence to the output file
            out_file.write(header + '\n')
            out_file.write(seq + '\n')
