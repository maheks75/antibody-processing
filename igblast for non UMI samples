#step 1- this step takes in the consensus file and arranges the seq count ie the no of times a sequence is present as headers
from Bio import SeqIO

input_fastq_file_5g = "il7_con_file.txt"

output_file_full = "il7_SEQ_COUNT_AS_HEADER.txt"
sequence_list_file = "umi_list.txt"

sequence_full_list = []
sequence_list_only = []

with open(output_file_full, 'w') as file:
    for i, record in enumerate(SeqIO.parse(input_fastq_file_5g, "fasta")):
        header_parts = record.description.split("_")
        header = f"> {header_parts[0]}"
        print(header)
        sequence_data_5g = str(record.seq)
        print(sequence_data_5g)
        sequence_full_list.append(f"{header}\n{sequence_data_5g}")
        sequence_list_only.append(header_parts[2].strip())

    

    for seq_full in sequence_full_list:
        file.write(seq_full + '\n')

# Save the sequence_list_only to a file
with open(sequence_list_file, 'w') as seq_file:
    for seq_part in sequence_list_only:
        seq_file.write(seq_part + '\n')

print("List of sequence headers only:", sequence_list_only)

#step 2 - PERFORM IGBLAST
import sys
from Bio import SeqIO
import subprocess
input_fasta = 'il7_SEQ_COUNT_AS_HEADER.txt'
output_fasta = 'IL7_try_igblast_output.tsv'
igblast_cmd = [
     'igblastn',
     '-query', input_fasta,
     '-out', output_fasta,
     '-germline_db_V', 'AlpacaV',
     '-germline_db_J', 'AlpacaJ',
     '-germline_db_D', 'AlpacaD',
     '-auxiliary_data','camelid_gl.aux',
     '-num_threads', '32',
     '-outfmt', '19',  
]
try:
    subprocess.run(igblast_cmd, check=True)
    print("IgBLAST analysis complete. Output saved to:", output_fasta)
except subprocess.CalledProcessError as e:  
    print("Error running IgBLAST:", e)

#STEP 3- PERFORM POST IGBLAST ANALYSIS
#igblast for phage samples
import pandas as pd
import sys
# Load the TSV file into a DataFrame
tsv_file_path = '4IL7_try_igblast_output.tsv'
df = pd.read_csv(tsv_file_path)

df = df.iloc[:, :53]
print(len(df.columns))

selected_columns = [0,1,2,3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]
print(list(enumerate(selected_df.columns)))
selected_df = df.iloc[:, selected_columns]

#print(selected_df)
# Group by the "sequence_aa" column and aggregate other columns
aggregation_dict = selected_df.groupby('sequence_aa').agg({
                   selected_df.columns[0]: 'sum',
                   selected_df.columns[1]: 'unique',
                   selected_df.columns[4]: 'first',
                   selected_df.columns[5]: 'first',
                   selected_df.columns[6]: 'first',
                   selected_df.columns[7]: 'first',
                   selected_df.columns[8]: 'first',
                   selected_df.columns[9]: 'first',
                   selected_df.columns[10]: 'first',
                   selected_df.columns[11]: 'first',
                   selected_df.columns[12]: 'first',
                   selected_df.columns[13]: 'first',
                   selected_df.columns[14]: 'first',
                   selected_df.columns[15]: 'first',
                   selected_df.columns[16]: 'first',
                   selected_df.columns[17]: 'first',
                   selected_df.columns[18]: 'first',
                   selected_df.columns[19]: 'first',
                   selected_df.columns[20]: 'first',
                   selected_df.columns[21]: 'first',
                   selected_df.columns[22]: 'first',
                   selected_df.columns[23]: 'first',
                   selected_df.columns[24]: 'first',
                   selected_df.columns[25]: 'first',
                   selected_df.columns[26]: 'first',
                   selected_df.columns[27]: 'first',
                   selected_df.columns[28]: 'first',
                   selected_df.columns[29]: 'first',
                   selected_df.columns[30]: 'first',
                   selected_df.columns[31]: 'first',
                   selected_df.columns[32]: 'first',
                   selected_df.columns[33]: 'first',
                   selected_df.columns[34]: 'first',
                   selected_df.columns[35]: 'first',
                   selected_df.columns[36]: 'first',
                   selected_df.columns[37]: 'first',
                   selected_df.columns[38]: 'first',
                   selected_df.columns[39]: 'first',
                   selected_df.columns[40]: 'first',
                   selected_df.columns[41]: 'first',
                   selected_df.columns[42]: 'first',
                   selected_df.columns[43]: 'first',
                   selected_df.columns[44]: 'first',
                   selected_df.columns[45]: 'first',
                   selected_df.columns[46]: 'first',
                   selected_df.columns[47]: 'first',
                   selected_df.columns[48]: 'first',
                   selected_df.columns[49]: 'first',
                   selected_df.columns[50]: 'first',
                   selected_df.columns[51]: 'first',
                   selected_df.columns[52]: 'first'}
).reset_index()


aggregation_dict.to_csv('igblast_output_try_file.tsv', index=False)
# Create a DataFrame with your UMI data
df = pd.read_csv('igblast_output_try_file.tsv')
#print(df.columns)
# Split the UMI strings by space and count the number of strings
#df['Number_of_Strings'] = df['umi'].apply(lambda x: len(x.split()))
df.to_csv('il7_Final_processed_igblast_file.tsv',index = False)
